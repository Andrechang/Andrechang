<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Computer Vision Resources - Andrechang</title>
        <!-- meta -->
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
        <meta name="generator" content="Jekyll" />
        <meta name="author" content="Andrechang" />
        <meta name="description" content="Andrechang's blog" />
        <meta name="keywords" content="" />
        <!-- atom -->
        <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="http://andrechang.github.io/atom.xml" />
        <link rel="shortcut icon" href="/images/shortcut.jpg" type="image/x-icon" />
        <!-- font-awesome -->
        <link href="//netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css" rel="stylesheet">
        <link href='http://fonts.useso.com/css?family=Spirax' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="http://andrechang.github.io/css/syntax.css">
        <link rel="stylesheet" href="http://andrechang.github.io/css/main.css">

        
        
    </head>

    <body>
    <!-- <body  data-spy="scroll" data-target=".toc" data-offset="20"> -->
        <div class="head fn-clear">
            <div class="header">
                <h1 class="logo">
                    <a href="http://andrechang.github.io"><i class="icon-anchor"></i></a>
                </h1>
                <nav class="nav">
                    <ul>
                        
                        
                        
                        <li class="nav-item ">
                            <a href="http://andrechang.github.io/index.html">
                                HOME
                            </a>
                            
                        </li>
                        
                        
                        
                        <li class="nav-item ">
                            <a href="http://andrechang.github.io/categories.html">
                                CATEGORIES
                            </a>
                            
                        </li>
                        
                        
                        
                        <li class="nav-item ">
                            <a href="http://andrechang.github.io/about.html">
                                ABOUT ME
                            </a>
                            
                        </li>
                        
                        
                        
                        <li class="nav-item ">
                            <a href="http://andrechang.github.io/links.html">
                                LINKS
                            </a>
                            
                        </li>
                        
                    </ul>
                </nav>
                <div class="follow">
                    
                    <a href="/atom.xml" target="_blank"><i class="icon-rss"></i></a>
                    
                    <a href="https://www.facebook.com/" target="_blank"><i class="icon-facebook"></i></a>
                    
                    <a href="https://github.com/Andrechang/" target="_blank"><i class="icon-github-alt"></i></a>
                    
                </div>
            </div>
        </div>

        <div class="contain fn-clear">
            <div class="container fn-clear">
                <!-- toc -->
                <!-- 
                <div class="main-left">
                    <div id="toc"></div>
                </div>
                 -->

                <div class="main">
                    <div class="article article-post">
    <h2 class="title">Computer Vision Resources</h2>
    <div class="info">
        <span class="info-title"><i class="icon-calendar"></i> Published: </span>
        <span class="info-date">12 Sep 2015</span>
        <span class="info-title"><i class="icon-folder-open"></i> Category: </span>
        <span class="info-link"><a href="http://andrechang.github.io/categories.html#computer_vision-ref" >computer_vision</a></span>
    </div>
    <div id="toc"></div>
    <h1 id="courses">Courses</h1>

<p><strong>Stanford CS231n: Convolutional Neural Networks for Visual Recognition</strong></p>

<ul>
  <li>homepage: <a href="http://cs231n.stanford.edu/">http://cs231n.stanford.edu/</a></li>
  <li>homepage: <a href="http://vision.stanford.edu/teaching/cs231n/index.html">http://vision.stanford.edu/teaching/cs231n/index.html</a></li>
  <li>syllabus: <a href="http://vision.stanford.edu/teaching/cs231n/syllabus.html">http://vision.stanford.edu/teaching/cs231n/syllabus.html</a></li>
  <li>github.io: <a href="http://cs231n.github.io/">http://cs231n.github.io/</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=NfnWJUyUJYU&amp;feature=youtu.be">https://www.youtube.com/watch?v=NfnWJUyUJYU&amp;feature=youtu.be</a></li>
  <li>video: <a href="http://pan.baidu.com/s/1pKsTivp">http://pan.baidu.com/s/1pKsTivp</a></li>
</ul>

<p><strong>Mobile Computer Vision</strong></p>

<p><img src="/assets/computer-vision/courses/Mobile_Computer_Vision_course-splash.png" alt="" /></p>

<p><a href="http://web.stanford.edu/class/cs231m/">http://web.stanford.edu/class/cs231m/</a></p>

<p><strong>CSCI1950-G Computational Photography</strong></p>

<p><img src="http://cs.brown.edu/courses/csci1950-g/images/montage_large.jpg" alt="" /></p>

<p><a href="http://cs.brown.edu/courses/csci1950-g/">http://cs.brown.edu/courses/csci1950-g/</a></p>

<p><strong>MIT CSAIL: 6.819/6.869: Advances in Computer Vision (Fall 2015)</strong></p>

<p><img src="http://6.869.csail.mit.edu/fa15/images/teaser.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://6.869.csail.mit.edu/fa15/index.html">http://6.869.csail.mit.edu/fa15/index.html</a></li>
</ul>

<p><strong>EECS 432 Advanced Computer Vision</strong></p>

<ul>
  <li>course website: <a href="http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html">http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/index.html</a>c</li>
  <li>handouts: <a href="http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html">http://www.ece.northwestern.edu/~yingwu/teaching/EECS432/EECS432_hand.html</a></li>
</ul>

<p><strong>EECS 286 Advanced Topics in Computer Vision</strong></p>

<ul>
  <li>homepage: <a href="http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm">http://faculty.ucmerced.edu/mhyang/course/eecs286/index.htm</a></li>
  <li>syllabus: <a href="http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm">http://faculty.ucmerced.edu/mhyang/course/eecs286/syllabus.htm</a></li>
  <li>lectures: <a href="http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm">http://faculty.ucmerced.edu/mhyang/course/eecs286/lecture.htm</a></li>
  <li>lecture(“How to get your CVPR paper rejected?”): <a href="http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx">http://faculty.ucmerced.edu/mhyang/course/eecs286/lectures/introduction.pptx</a></li>
</ul>

<p><strong>CS280: Computer Vision (University of California Berkeley)</strong></p>

<ul>
  <li>homepage: <a href="http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html">http://www-inst.eecs.berkeley.edu/~cs280/sp15/index.html</a></li>
  <li>lectures: <a href="http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/">http://docs.huihoo.com/computer-vision/berkeley/cs280-computer-vision/</a></li>
</ul>

<p><strong>CSCI2951-T Data-driven Computer Vision (Spring 2016)</strong></p>

<p><img src="http://cs.brown.edu/courses/csci2951-t/images/detection_teaser.png" alt="" /></p>

<ul>
  <li>instructor: Genevieve Patterson</li>
  <li>homepage: <a href="http://cs.brown.edu/courses/csci2951-t/">http://cs.brown.edu/courses/csci2951-t/</a></li>
</ul>

<h1 id="edge-detection">Edge detection</h1>

<p><strong>Image-feature-detection-using-Phase-Stretch-Transform</strong></p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/4/45/PST_edge_detection_on_barbara_image.tif" alt="" /></p>

<ul>
  <li>github: <a href="https://github.com/JalaliLabUCLA/Image-feature-detection-using-Phase-Stretch-Transform">https://github.com/JalaliLabUCLA/Image-feature-detection-using-Phase-Stretch-Transform</a></li>
  <li>wikipedia: <a href="https://en.wikipedia.org/wiki/Phase_stretch_transform">https://en.wikipedia.org/wiki/Phase_stretch_transform</a></li>
</ul>

<h1 id="images-denoising">Images Denoising</h1>

<p><strong>Fast Burst Images Denoising(SIGGRAPH Asia 2014. CUHK, Microsoft Research)</strong></p>

<p><img src="http://personal.ie.cuhk.edu.hk/~lz013/projects/burstdenoising/intro.png" alt="" /></p>

<ul>
  <li>project: <a href="http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html">http://personal.ie.cuhk.edu.hk/~lz013/projects/BurstDenoising.html</a></li>
  <li>paper: <a href="http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf">http://personal.ie.cuhk.edu.hk/~lz013/papers/burstdenoising.pdf</a></li>
</ul>

<p><strong>Robust non-linear regression analysis: A greedy approach employing kernels and application to image denoising (KGARD)</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.00595">http://arxiv.org/abs/1601.00595</a></li>
  <li>code(Matlab): <a href="http://bouboulis.mysch.gr/kernels.html">http://bouboulis.mysch.gr/kernels.html</a></li>
</ul>

<p><strong>Blind Image Denoising via Dependent Dirichlet Process Tree</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.03117">http://arxiv.org/abs/1601.03117</a></li>
</ul>

<h1 id="deblur">Deblur</h1>

<p><strong>Good Regions to Deblur</strong></p>

<ul>
  <li>project page: <a href="https://eng.ucmerced.edu/people/zhu/GoodRegion.html">https://eng.ucmerced.edu/people/zhu/GoodRegion.html</a></li>
  <li>paper: <a href="https://eng.ucmerced.edu/people/zhu/ECCV12.pdf">https://eng.ucmerced.edu/people/zhu/ECCV12.pdf</a></li>
  <li>code(Matlab): <a href="https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip">https://eng.ucmerced.edu/people/zhu/ECCV12_code.zip</a></li>
</ul>

<h1 id="painting">Painting</h1>

<p><strong>Real-Time Gradient-Domain Painting (SIGGRAPH 2009)</strong></p>

<ul>
  <li>homepage: <a href="http://graphics.cs.cmu.edu/projects/gradient-paint/">http://graphics.cs.cmu.edu/projects/gradient-paint/</a></li>
  <li>paper: <a href="http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf">http://graphics.cs.cmu.edu/projects/gradient-paint/grad.light.r2226.pdf</a></li>
</ul>

<p><strong>Combining Sketch and Tone for Pencil Drawing Production (NPAR 2012 Best Paper Award)</strong></p>

<p><img src="/assets/computer-vision/pencil_drawing.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm">http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/pencil_drawing.htm</a></li>
  <li>paper: <a href="http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf">http://www.cse.cuhk.edu.hk/~leojia/projects/pencilsketch/npar12_pencil.pdf</a></li>
  <li>github: <a href="https://github.com/fumin/pencil">https://github.com/fumin/pencil</a></li>
</ul>

<hr />

<p><strong>RGB-W: When Vision Meets Wireless</strong></p>

<p><img src="http://vision.stanford.edu/pubimg/rgbw15_1.png" alt="" /></p>

<ul>
  <li>paper: <a href="http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf">http://vision.stanford.edu/pdf/RGBW_ICCV15.pdf</a></li>
</ul>

<hr />

<p><strong>Computer Vision Datasets</strong></p>

<ul>
  <li>website: <a href="http://clickdamage.com/sourcecode/index.html">http://clickdamage.com/sourcecode/index.html</a></li>
  <li>code: <a href="http://clickdamage.com/sourcecode/cv_datasets.php">http://clickdamage.com/sourcecode/cv_datasets.php</a></li>
  <li>BaiduPan: <a href="http://pan.baidu.com/s/1pJmqD4n">http://pan.baidu.com/s/1pJmqD4n</a></li>
</ul>

<p><strong>A Computational Approach for Obstruction-Free Photography</strong></p>

<p><img src="/assets/computer-vision/A_Computational_Approach_for_Obstruction-Free_Photography.jpg" alt="" /></p>

<ul>
  <li>paper: <a href="https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf">https://people.csail.mit.edu/mrub/papers/ObstructionFreePhotograpy_SIGGRAPH2015.pdf</a></li>
</ul>

<p><strong>My Text in Your Handwriting</strong></p>

<p><img src="http://visual.cs.ucl.ac.uk/pubs/handwriting/img/results.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://visual.cs.ucl.ac.uk/pubs/handwriting/">http://visual.cs.ucl.ac.uk/pubs/handwriting/</a></li>
  <li>paper: <a href="http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf">http://visual.cs.ucl.ac.uk/pubs/handwriting/handwriting_visual_main.pdf</a></li>
</ul>

<h1 id="bag-of-words">Bag Of Words</h1>

<h1 id="activity-recognition">Activity Recognition</h1>

<p><strong>Latent Hierarchical Model for Activity Recognition</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1503.01820">http://arxiv.org/abs/1503.01820</a></li>
  <li>github: <a href="https://github.com/louxi11/activity_recognition">https://github.com/louxi11/activity_recognition</a></li>
  <li>author page: <a href="https://staff.fnwi.uva.nl/n.hu/">https://staff.fnwi.uva.nl/n.hu/</a></li>
</ul>

<h1 id="license-plate-recognition">License Plate Recognition</h1>

<ul>
  <li>website: <a href="http://www.openalpr.com/">http://www.openalpr.com/</a></li>
  <li>github: <a href="https://github.com/openalpr/openalpr">https://github.com/openalpr/openalpr</a></li>
  <li>tech reciew: <a href="http://arstechnica.com/business/2015/12/new-open-source-license-plate-reader-software-lets-you-make-your-own-hot-list/">http://arstechnica.com/business/2015/12/new-open-source-license-plate-reader-software-lets-you-make-your-own-hot-list/</a></li>
</ul>

<p><strong>Reading Car License Plates Using Deep Convolutional Neural Networks and LSTMs</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.05610">http://arxiv.org/abs/1601.05610</a></li>
</ul>

<h1 id="image-retrieval">Image Retrieval</h1>

<p><strong>Multi-modal image retrieval with random walk on multi-layer graphs</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1607.03406">http://arxiv.org/abs/1607.03406</a></li>
</ul>

<h1 id="image-summary">Image Summary</h1>

<p><strong>Summarizing Visual Data Using Bidirectional Similarity</strong></p>

<ul>
  <li>homepage: <a href="http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html">http://denis.simakov.info/weizmann/summarization_talk_20101116/summarization.html</a></li>
  <li>paper: <a href="http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf">http://www.wisdom.weizmann.ac.il/~vision/VisualSummary/bidirectional_similarity_CVPR2008.pdf</a></li>
</ul>

<h1 id="image-retargetingediting">Image Retargeting/Editing</h1>

<p><strong>PatchMatch: A Randomized Correspondence Algorithm for Structural Image Editing</strong></p>

<p><img src="http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch_title.png" alt="" /></p>

<ul>
  <li>homepage(paper+code): <a href="http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/">http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/</a></li>
  <li>paper: <a href="http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf">http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch.pdf</a></li>
  <li>code: <a href="http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip">http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/patchmatch-2.1.zip</a></li>
</ul>

<p><strong>The Generalized PatchMatch Correspondence Algorithm</strong></p>

<p><img src="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/gpm_teaser.png" alt="" /></p>

<ul>
  <li>homapage(paper+code): <a href="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php">http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/index.php</a></li>
  <li>paper: <a href="http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf">http://gfx.cs.princeton.edu/pubs/Barnes_2010_TGP/generalized_pm.pdf</a></li>
  <li>code: <a href="http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip">http://www.cs.princeton.edu/gfx/pubs/Barnes_2009_PAR/patchmatch-2.0.zip</a></li>
</ul>

<h1 id="image-editing">Image Editing</h1>

<p><strong>Seamless Image Editing</strong></p>

<p><img src="http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/img/teaser.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/">http://www.cmlab.csie.ntu.edu.tw/~dreamway/seamless/</a></li>
</ul>

<h1 id="image-inpaiting">Image Inpaiting</h1>

<p><strong>Patch-based Texture Synthesis for Image Inpainting</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.01576">http://arxiv.org/abs/1605.01576</a></li>
</ul>

<h1 id="image-dithering">Image Dithering</h1>

<p><strong>Image Dithering: Eleven Algorithms and Source Code</strong></p>

<ul>
  <li>blog: <a href="http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/">http://www.tannerhelland.com/4660/dithering-eleven-algorithms-source-code/</a></li>
</ul>

<h1 id="image-enhancement">Image Enhancement</h1>

<p><strong>LIME: A Method for Low-light IMage Enhancement</strong></p>

<p><img src="http://photo.weibo.com/2578103464/wbphotos/large/mid/3971098712490115/pid/99aabca8jw1f3ibhb6o8ej20ck09cmzl" alt="" /></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.05034">http://arxiv.org/abs/1605.05034</a></li>
  <li>github: <a href="http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip">http://cs.tju.edu.cn/orgs/vision/~xguo/code/LIME.zip</a></li>
  <li>author homepage: <a href="http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm">http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm</a></li>
</ul>

<p><strong>SelPh: Progressive Learning and Support of Manual Photo Color Enhancement</strong></p>

<p><img src="http://koyama.xyz/project/SelPh/teaser1.gif" alt="" /></p>

<ul>
  <li>homepage: <a href="http://koyama.xyz/project/SelPh/">http://koyama.xyz/project/SelPh/</a></li>
  <li>paper: <a href="http://koyama.xyz/project/SelPh/chi2016_paper.pdf">http://koyama.xyz/project/SelPh/chi2016_paper.pdf</a></li>
  <li>bitbucket: <a href="https://bitbucket.org/yukikoyama/selph/">https://bitbucket.org/yukikoyama/selph/</a></li>
</ul>

<h1 id="image-resizing">Image Resizing</h1>

<ul>
  <li>blog: <a href="http://parellagram.com/posts/carving">http://parellagram.com/posts/carving</a></li>
  <li>github: <a href="https://github.com/aaparella/carve">https://github.com/aaparella/carve</a></li>
</ul>

<h1 id="image-cloning">Image Cloning</h1>

<p><strong>Coordinates for Instant Image Cloning (SIGGRAPH 2009)</strong></p>

<p><img src="http://www.cs.huji.ac.il/~danix/mvclone/teaser.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.cs.huji.ac.il/~danix/mvclone/">http://www.cs.huji.ac.il/~danix/mvclone/</a></li>
  <li>paper: <a href="http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf">http://www.cs.huji.ac.il/~danix/mvclone/files/mvc-final-opt.pdf</a></li>
</ul>

<h1 id="image-compositing">Image Compositing</h1>

<p><strong>Interactive Digital Photomontage (SIGGRAPH 2004)</strong></p>

<ul>
  <li>homepage: <a href="http://grail.cs.washington.edu/projects/photomontage/">http://grail.cs.washington.edu/projects/photomontage/</a></li>
  <li>code: <a href="http://grail.cs.washington.edu/projects/photomontage/release/">http://grail.cs.washington.edu/projects/photomontage/release/</a></li>
  <li>paper: <a href="http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf">http://grail.cs.washington.edu/projects/photomontage/photomontage.pdf</a></li>
  <li>paper: <a href="http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage">http://www.researchgate.net/publication/2941744_Interactive_Digital_Photomontage</a></li>
</ul>

<p><strong>Panorama Stitching</strong></p>

<p><strong>CS510 Visual Computing, Project 2: Panorama Stitching</strong></p>

<p><a href="http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/">http://web.cecs.pdx.edu/~kstew2/cs510vision/stitcher/</a></p>

<h1 id="image-stylization">Image Stylization</h1>

<p><strong>stylize: Regressor based image stylization</strong></p>

<p><img src="https://raw.githubusercontent.com/Newmu/stylize/master/resources/iggy.gif" alt="" /></p>

<ul>
  <li>github: <a href="https://github.com/Newmu/stylize">https://github.com/Newmu/stylize</a></li>
</ul>

<h1 id="image-haze-removal">Image Haze Removal</h1>

<p><strong>Single Image Haze Removal</strong></p>

<ul>
  <li>project page: <a href="http://research.microsoft.com/en-us/um/people/kahe/cvpr09/">http://research.microsoft.com/en-us/um/people/kahe/cvpr09/</a></li>
</ul>

<p><strong>DehazeNet: An End-to-End System for Single Image Haze Removal</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.07661">http://arxiv.org/abs/1601.07661</a></li>
</ul>

<h1 id="graph-cut">Graph Cut</h1>

<h1 id="grabcut">GrabCut</h1>

<p><strong>“GrabCut” — Interactive Foreground Extraction using Iterated Graph Cuts</strong></p>

<ul>
  <li>paper: <a href="http://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf">http://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf</a></li>
</ul>

<p><strong>OpenCV 3.1: Interactive Foreground Extraction using GrabCut Algorithm</strong></p>

<p><a href="http://docs.opencv.org/master/d8/d83/tutorial_py_grabcut.html#gsc.tab=0">http://docs.opencv.org/master/d8/d83/tutorial_py_grabcut.html#gsc.tab=0</a></p>

<h1 id="image-stitching">Image Stitching</h1>

<p><strong>Natural and Seamless Image Composition with Color Control</strong></p>

<p><a href="http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf">http://www3.ntu.edu.sg/home/asjfcai/tip04594.pdf</a></p>

<p><strong>Object-aware Gradient-Domain Image Compositing</strong></p>

<p><a href="http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf">http://www.cg.cs.tu-bs.de/media/publications/Eisemann11OAG.pdf</a></p>

<p><strong>Improving Image Matting using Comprehensive Sampling Sets</strong></p>

<p><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Shahrian_Improving_Image_Matting_2013_CVPR_paper.pdf</a></p>

<p><strong>Multi-scale Image Harmonization</strong></p>

<p><img src="http://gvi.seas.harvard.edu/sites/all/files/paper-rep-images/harmonization_teaser_3.png" alt="" /></p>

<ul>
  <li>homepage: <a href="http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization">http://gvi.seas.harvard.edu/paper/multiscale-image-harmonization</a></li>
  <li>paper: <a href="http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf">http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pdf</a></li>
  <li>slides: <a href="http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx">http://gvi.seas.harvard.edu/sites/all/files/Harmonization_SIGGRAPH10.pptx</a></li>
</ul>

<p><strong>Drag-and-Drop Pasting</strong></p>

<p><a href="http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf">http://research.microsoft.com/pubs/69331/dragdroppasting_siggraph06.pdf</a></p>

<p><strong>Cross Dissolve Without Cross Fade: Preserving Contrast, Color and Salience in Image Compositing</strong></p>

<p><a href="https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf">https://www.cl.cam.ac.uk/research/rainbow/projects/compositing/EG06-Cross-Dissolve-Without-Cross-Fade.pdf</a></p>

<p><strong>Snap Image Composition</strong></p>

<p><a href="http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf">http://www.cs.huji.ac.il/~peleg/papers/SnapComposition.pdf</a></p>

<p><strong>Stitching Stabilizer: Two-frame-stitching Video Stabilization for Embedded Systems</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.06678">http://arxiv.org/abs/1603.06678</a></li>
</ul>

<p><strong>Stitching and Matting</strong></p>

<ul>
  <li>lectures: <a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf">http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2015/bil721/lectures/w06-stitching-matting.pdf</a></li>
</ul>

<p><strong>Image Stitching</strong></p>

<ul>
  <li>lectures: <a href="https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf">https://courses.engr.illinois.edu/cs498dwh/fa2010/lectures/Lecture%2017%20-%20Photo%20Stitching.pdf</a></li>
</ul>

<p><strong>Graphics isn’t all about 3-D</strong></p>

<ul>
  <li>
    <p>lectures: <a href="http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf">http://www.cs.cmu.edu/afs/cs/academic/class/15462-s09/www/lec/25/lec25.pdf</a></p>
  </li>
  <li>
    <p>slides: <a href="http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5">http://upcommons.upc.edu/bitstream/handle/2099.1/22861/PujolAlba-TFG-FinalReport.pdf;jsessionid=7AE46AE2A5420F75760F246381D429BC?sequence=5</a></p>
  </li>
</ul>

<p><strong>Assignment: Image stitching with RANSAC</strong></p>

<ul>
  <li>assignments: <a href="https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf">https://people.cs.umass.edu/~elm/Teaching/Docs/assign_RANSAC.pdf</a></li>
</ul>

<p><strong>OpenCV panorama stitching</strong></p>

<ul>
  <li>blog: <a href="http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/">http://www.pyimagesearch.com/2016/01/11/opencv-panorama-stitching/</a></li>
</ul>

<p><strong>Real-time panorama and image stitching with OpenCV</strong></p>

<ul>
  <li>blog: <a href="http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/">http://www.pyimagesearch.com/2016/01/25/real-time-panorama-and-image-stitching-with-opencv/</a></li>
</ul>

<h1 id="image-super-resolution">Image Super-Resolution</h1>

<p><strong>Super-Resolution From a Single Image</strong></p>

<ul>
  <li>project: <a href="http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html">http://www.wisdom.weizmann.ac.il/~vision/SingleImageSR.html</a></li>
  <li>paper: <a href="http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf">http://www.wisdom.weizmann.ac.il/~vision/single_image_SR/files/single_image_SR.pdf</a></li>
</ul>

<p><strong>Aperture-scanning Fourier ptychography for 3D refocusing and super-resolution macroscopic imaging</strong></p>

<ul>
  <li>paper: <a href="http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf">http://www.its.caltech.edu/~roarke/research/FPM/FPM_Aperture_Scanning.pdf</a></li>
  <li>slides: <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138">http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6754138</a></li>
</ul>

<p><strong>Single Image Super-Resolution from Transformed Self-Exemplars</strong></p>

<ul>
  <li>homepage: <a href="https://sites.google.com/site/jbhuang0604/publications/struct_sr">https://sites.google.com/site/jbhuang0604/publications/struct_sr</a></li>
  <li>github: <a href="https://github.com/jbhuang0604/SelfExSR">https://github.com/jbhuang0604/SelfExSR</a></li>
</ul>

<h1 id="photo-collage">Photo Collage</h1>

<p><strong>AutoCollage (SIGGRAPH 2006)</strong></p>

<p><img src="/assets/computer-vision/video_summary/collage1fullcomp.jpg" alt="" /></p>

<ul>
  <li>intro: “Autocollage defines different energies to encourage the selection of a representative set of images, 
select particular object classes, and encourage a spatially efficient and seamless layout. 
The optimization is divided into a sequence of steps: from static ranking of images, through region of interest detection, 
optimal packing by the branch-and-bound algorithm, and lastly graph-cut alpha expansion. 
The core packing algorithm is limited; for example, user interaction cannot be integrated. 
The packing algorithm cannot deal with images with multiple salient regions which are assigned different weights.
Further, the blending still may bring artifacts on the boundaries of different images.”</li>
  <li>homepage: <a href="http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx">http://research.microsoft.com/en-us/projects/i3l/autocollage.aspx</a></li>
  <li>paper: <a href="http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf">http://research.microsoft.com/pubs/67894/autocollage_rotheretal_siggraph2006.pdf</a></li>
  <li>slides: <a href="http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip">http://research.microsoft.com/en-us/UM/cambridge/projects/VisionImageVideoEditing/autocollage/TalkSiggraph2006Compressed.zip</a></li>
  <li>demo: <a href="http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/">http://research.microsoft.com/en-us/um/cambridge/projects/autocollage/</a></li>
</ul>

<p><strong>Picture Collage (2006)</strong></p>

<ul>
  <li>paper: <a href="http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf">http://research.microsoft.com/en-us/um/people/jiansun/papers/PictureCollage_CVPR2006.pdf</a></li>
  <li>paper: <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.5727</a></li>
</ul>

<p><strong>Picture Collage (2009)</strong></p>

<ul>
  <li>intro: “formulate the picture collage creation problem in a conditional random field model, which integrates
image salience, canvas constraint, natural preference, and user interaction”</li>
  <li>paper: <a href="http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf">http://mmlab.ie.cuhk.edu.hk/archive/2009/07_Picture.pdf</a></li>
</ul>

<p><strong>Efficient Optimization of Photo Collage</strong></p>

<ul>
  <li>paper: <a href="http://research.microsoft.com/pubs/80783/Collage_techreport.pdf">http://research.microsoft.com/pubs/80783/Collage_techreport.pdf</a></li>
</ul>

<h1 id="video-collage">Video Collage</h1>

<p><strong>Video collage: A novel presentation of video sequence (ICME 2007)</strong></p>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.130.3728&amp;rep=rep1&amp;type=pdf</a></p>

<p><strong>Stained-Glass Visualization for Highly Condensed Video Summaries (ICME 2004)</strong></p>

<p><a href="https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf">https://www.fxpal.com/publications/stained-glass-visualization-for-highly-condensed-video-summaries.pdf</a></p>

<p><strong>Stained Glass Photo Collages</strong></p>

<p><a href="http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf">http://uist.acm.org/archive/adjunct/2004/pdf/posters/p7-girgensohn.pdf</a></p>

<p><strong>Visual Storylines: Semantic Visualization of Movie Sequence</strong></p>

<ul>
  <li>paper: <a href="http://cg.cs.tsinghua.edu.cn/papers/C&amp;G2012_videostoryline.pdf">http://cg.cs.tsinghua.edu.cn/papers/C&amp;G2012_videostoryline.pdf</a></li>
  <li>paper: <a href="http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf">http://cg.cs.tsinghua.edu.cn/people/~taochen/papers/VisualStorylines.pdf</a></li>
</ul>

<p><strong>Video collage: presenting a video sequence using a single image</strong></p>

<p><a href="http://iris.usc.edu/people/yangbo/papers/vcj08.pdf">http://iris.usc.edu/people/yangbo/papers/vcj08.pdf</a></p>

<p><strong>Efficient Optimization of Photo Collage</strong></p>

<p><a href="http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf">http://research.microsoft.com/en-us/people/yichenw/collage_techreport.pdf</a></p>

<p><strong>Puzzle-like Collage (2010)</strong></p>

<p><a href="http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf">http://webee.technion.ac.il/~ayellet/Ps/10-PuzzleCollage.pdf</a></p>

<p><strong>Browsing Large Image Datasets through Voronoi Diagrams</strong></p>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=576998825C3E40A32826A00B64089DF6?doi=10.1.1.230.5997&amp;rep=rep1&amp;type=pdf</a></p>

<p><strong>Content-aware Photo Collage Using Circle Packing (NJU. TVCG 2014)</strong></p>

<p><img src="/assets/computer-vision/video_summary/Photo_Collage_Flowchart.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html">http://cs.nju.edu.cn/ywguo/PhotoCollage/Index.html</a></li>
  <li>paper: <a href="http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf">http://cs.nju.edu.cn/ywguo/webs/paperdownload/Content-aware%20Photo%20Collage%20Using%20Circle%20Packing.pdf</a></li>
  <li>demo: <a href="http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html">http://cs.nju.edu.cn/ywguo/PhotoCollage/dload.html</a></li>
</ul>

<p><strong>Automatic Generation of Social Media Snippets for Mobile Browsing (Microsoft Research. ACM Multimedia 2013)</strong></p>

<ul>
  <li>homepage: <a href="http://research.microsoft.com/apps/pubs/default.aspx?id=204877">http://research.microsoft.com/apps/pubs/default.aspx?id=204877</a></li>
  <li>paper: <a href="http://research.microsoft.com/pubs/204877/mm035-yin.pdf">http://research.microsoft.com/pubs/204877/mm035-yin.pdf</a></li>
</ul>

<h1 id="video-tapestry">Video Tapestry</h1>

<p><strong>Digital Tapestry (MSR. CVPR 2005)</strong></p>

<ul>
  <li>intro: “formulates the selection of salient regions and their placement together as a Markov random field (MRF) problem. 
Each image is represented as a set of blocks, and the multiple-class labeling problem with non-metric
constraints is optimized by “truncating” the non-regular energy.
However, artifacts are also introduced along the boundaries of neighboring salient regions coming from two different images
in digital tapestry, although some artifact removal methods can be used”</li>
  <li>homepage: <a href="http://research.microsoft.com/apps/pubs/default.aspx?id=67404">http://research.microsoft.com/apps/pubs/default.aspx?id=67404</a></li>
  <li>paper: <a href="http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf">http://pub.ist.ac.at/~vnk/papers/tapestry_cvpr05.pdf</a></li>
</ul>

<p><strong>Video Tapestries with Continuous Temporal Zoom (Princeton. SIGGRAPH 2010)</strong></p>

<p><img src="http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/teaser.png" alt="" /></p>

<ul>
  <li>homepage: <a href="http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php">http://gfx.cs.princeton.edu/gfx/pubs/Barnes_2010_VTW/index.php</a></li>
  <li>paper: <a href="http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf">http://www.connellybarnes.com/work/publications/2010_tapestry_electronic.pdf</a></li>
</ul>

<h1 id="video-creativity">Video Creativity</h1>

<p><strong>6 Seconds of Sound and Vision: Creativity in Micro-Videos (CVPR 2014)</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1411.4080">http://arxiv.org/abs/1411.4080</a></li>
  <li>homepage: <a href="http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/">http://www.di.unito.it/~schifane/dataset/vine-dataset-cvpr14/</a></li>
</ul>

<h1 id="video-highlights">Video Highlights</h1>

<p><strong>Ranking Domain-specific Highlights by Analyzing Edited Videos (ECCV 2014)</strong></p>

<p><img src="http://aliensunmin.github.io/project/at-a-glance/highlight_teaser.png" alt="" /></p>

<ul>
  <li>intro: use a dataset obtained by crawling Youtube data. find pairs of raw and edited videos, used in training,
by matching all pairs of videos within a certain category(e.g. gymnastics).
The size of their dataset is, however, limited by the availability of domain-specific videos in both raw and edited forms.</li>
  <li>homepage: <a href="http://aliensunmin.github.io/project/at-a-glance/">http://aliensunmin.github.io/project/at-a-glance/</a></li>
  <li>paper: <a href="http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf">http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014rdh.pdf</a></li>
  <li>paper: <a href="https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit">https://drive.google.com/file/d/0ByJgUdTb1N2CM3Y5VU1BRjlmR3c/edit</a></li>
  <li>tech: <a href="https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view">https://drive.google.com/file/d/0ByJgUdTb1N2CM1ktb1N4RVV3Mzg/view</a></li>
  <li>github: <a href="https://github.com/aliensunmin/DomainSpecificHighlight">https://github.com/aliensunmin/DomainSpecificHighlight</a></li>
</ul>

<p><strong>Salient Montages from Unconstrained Videos</strong></p>

<p><img src="http://aliensunmin.github.io/project/at-a-glance/montage_teaser.png" alt="" /></p>

<ul>
  <li>homepage: <a href="http://aliensunmin.github.io/project/at-a-glance/">http://aliensunmin.github.io/project/at-a-glance/</a></li>
  <li>paper: <a href="http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf">http://grail.cs.washington.edu/wp-content/uploads/2015/08/sun2014smf.pdf</a></li>
  <li>paper: <a href="https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit">https://drive.google.com/file/d/0ByJgUdTb1N2CbzNYTjdxX0ZiRmc/edit</a></li>
  <li>github: <a href="https://github.com/aliensunmin/salientMontages">https://github.com/aliensunmin/salientMontages</a></li>
</ul>

<p><strong>Unsupervised Extraction of Video Highlights Via Robust Recurrent Auto-encoders (ICCV 2015)</strong></p>

<ul>
  <li>intro: rely on an assumption that highlights of an event category are more frequently captured in short videos than non-highlights</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.01442">http://arxiv.org/abs/1510.01442</a></li>
</ul>

<p><strong>Highlight Detection with Pairwise Deep Ranking for First-Person Video Summarization</strong></p>

<ul>
  <li>paper: <a href="http://research.microsoft.com/apps/pubs/default.aspx?id=264919">http://research.microsoft.com/apps/pubs/default.aspx?id=264919</a></li>
</ul>

<h1 id="video-summarization">Video Summarization</h1>

<p><strong>Creating Summaries from User Videos (ECCV 2014)</strong></p>

<p><img src="http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum.png" alt="" /></p>

<ul>
  <li>project page: <a href="https://people.ee.ethz.ch/~gyglim/vsum/index.php">https://people.ee.ethz.ch/~gyglim/vsum/index.php</a></li>
  <li>paper: <a href="https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf">https://people.ee.ethz.ch/~gyglim/vsum/GygliECCV14_vsum.pdf</a></li>
  <li>paper: <a href="http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf">http://www.vision.ee.ethz.ch/~hegrabne/papers/Gygli2014CreatingSummariesfrom.pdf</a></li>
  <li>code: <a href="https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code">https://people.ee.ethz.ch/~gyglim/vsum/index.php#sf_code</a></li>
</ul>

<p><strong>Video Summarization by Learning Submodular Mixtures of Objectives (CVPR 2015)</strong></p>

<p><img src="http://www.vision.ee.ethz.ch/~hegrabne/visualInterestingness/vsum2.jpg" alt="" /></p>

<ul>
  <li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Gygli_Video_Summarization_by_2015_CVPR_paper.pdf</a></li>
</ul>

<p><strong>TVSum: Summarizing Web Videos Using Titles</strong></p>

<p><img src="https://qph.is.quoracdn.net/main-qimg-0c0bb88876258e99272200655e2dc2ea?convert_to_webp=true" alt="" /></p>

<ul>
  <li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Song_TVSum_Summarizing_Web_2015_CVPR_paper.pdf</a></li>
</ul>

<p><strong>Summarizing While Recording: Context-Based Highlight Detection for Egocentric Videos</strong></p>

<ul>
  <li>paper: <a href="http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf">http://www.umiacs.umd.edu/~morariu/publications/LinEgocentricICCVW15.pdf</a></li>
</ul>

<p><strong>Video Summarization with Long Short-term Memory</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.08110">http://arxiv.org/abs/1605.08110</a></li>
</ul>

<h1 id="face-detection">Face Detection</h1>

<p><strong>Build a Face Detection App Using Node.js and OpenCV</strong></p>

<p><a href="http://www.sitepoint.com/face-detection-nodejs-opencv/">http://www.sitepoint.com/face-detection-nodejs-opencv/</a></p>

<p><strong>FaceTracker: Real time deformable face tracking in C++ with OpenCV 2</strong></p>

<ul>
  <li>github: <a href="https://github.com/kylemcdonald/FaceTracker">https://github.com/kylemcdonald/FaceTracker</a></li>
</ul>

<p><strong>A Fast and Accurate Unconstrained Face Detector</strong></p>

<p><img src="https://github.com/CitrusRokid/OpenNPD" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.cbsr.ia.ac.cn/users/scliao/projects/npdface/index.html">http://www.cbsr.ia.ac.cn/users/scliao/projects/npdface/index.html</a></li>
  <li>github: <a href="https://github.com/CitrusRokid/OpenNPD">https://github.com/CitrusRokid/OpenNPD</a></li>
</ul>

<p><strong>libfacedetection: A binary library for face detection in images. You can use it free of charge with any purpose</strong></p>

<ul>
  <li>github: <a href="https://github.com/ShiqiYu/libfacedetection">https://github.com/ShiqiYu/libfacedetection</a></li>
</ul>

<p><strong>jQuery Face Detection Plugin: A jQuery plugin to detect faces on images, videos and canvases</strong></p>

<ul>
  <li>website: <a href="http://facedetection.jaysalvat.com/">http://facedetection.jaysalvat.com/</a></li>
  <li>github: <a href="https://github.com/jaysalvat/jquery.facedetection">https://github.com/jaysalvat/jquery.facedetection</a></li>
</ul>

<h1 id="slam">SLAM</h1>

<p><strong>Why SLAM Matters, The Future of Real-Time SLAM, and Deep Learning vs SLAM</strong></p>

<ul>
  <li>blog: <a href="http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1">http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html?m=1</a></li>
</ul>

<p><strong>一起做RGB-D SLAM</strong></p>

<ul>
  <li>blog: <a href="http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/">http://www.cnblogs.com/gaoxiang12/tag/%E4%B8%80%E8%B5%B7%E5%81%9ARGB-D%20SLAM/</a></li>
  <li>github: <a href="https://github.com/gaoxiang12/rgbd-slam-tutorial-gx">https://github.com/gaoxiang12/rgbd-slam-tutorial-gx</a></li>
</ul>

<p><strong>PySceneDetect: a command-line application and a Python library for automatically detecting scene changes in video files</strong></p>

<ul>
  <li>homepage: <a href="http://pyscenedetect.readthedocs.org/en/latest/">http://pyscenedetect.readthedocs.org/en/latest/</a></li>
</ul>

<p><strong>The Future of Real-Time SLAM and Deep Learning vs SLAM</strong></p>

<ul>
  <li>blog: <a href="http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html">http://www.computervisionblog.com/2016/01/why-slam-matters-future-of-real-time.html</a></li>
</ul>

<h1 id="ocr">OCR</h1>

<p><strong>Ocular: a state-of-the-art historical OCR system</strong></p>

<ul>
  <li>github: <a href="https://github.com/tberg12/ocular">https://github.com/tberg12/ocular</a></li>
</ul>

<p><strong>【OCR/机器学习/搜索引擎】基于 Tesseract的图文识别搜</strong></p>

<ul>
  <li>github: <a href="https://github.com/daijiale/OCR_FontsSearchEngine">https://github.com/daijiale/OCR_FontsSearchEngine</a></li>
</ul>

<h1 id="papers">Papers</h1>

<p><strong>Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects</strong></p>

<p><img src="http://grail.cs.washington.edu/projects/size/images/teaser.jpg" alt="" /></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.00753">http://arxiv.org/abs/1602.00753</a></li>
  <li>project page: <a href="http://grail.cs.washington.edu/projects/size/">http://grail.cs.washington.edu/projects/size/</a></li>
</ul>

<p><strong>Atoms of recognition in human and computer vision</strong></p>

<p><img src="http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/cover.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html">http://www.wisdom.weizmann.ac.il/~dannyh/Mircs/mircs.html</a></li>
  <li>paper: <a href="https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf">https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20150929153916/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Paper.pdf</a></li>
</ul>

<p><strong>Live Texturing of Augmented Reality Characters from Colored Drawings</strong></p>

<p><img src="https://www.disneyresearch.com/wp-content/uploads/Live-Texturing-of-Augmented-Reality-Characters-from-Colored-Drawings-Image-1024x576.png" alt="" /></p>

<ul>
  <li>homepage: <a href="https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/">https://www.disneyresearch.com/publication/live-texturing-of-augmented-reality-characters/</a></li>
</ul>

<p><strong>Colorization for Image Compression</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1606.06314">http://arxiv.org/abs/1606.06314</a></li>
</ul>

<p><strong>Face2Face: Real-time Face Capture and Reenactment of RGB Videos</strong></p>

<p><img src="http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/teaser.jpg" alt="" /></p>

<ul>
  <li>project page: <a href="http://www.graphics.stanford.edu/~niessner/thies2016face.html">http://www.graphics.stanford.edu/~niessner/thies2016face.html</a></li>
  <li>paper: <a href="http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf">http://www.graphics.stanford.edu/~niessner/papers/2016/1facetoface/thies2016face.pdf</a></li>
</ul>

<h1 id="applications">Applications</h1>

<p><strong>Target acquired: Finding targets in drone and quadcopter video streams using Python and OpenCV</strong></p>

<p><a href="http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/">http://www.pyimagesearch.com/2015/05/04/target-acquired-finding-targets-in-drone-and-quadcopter-video-streams-using-python-and-opencv/</a></p>

<p><strong>FaceDirector: Continuous Control of Facial Performance in Video</strong></p>

<p><img src="https://www.disneyresearch.com/wp-content/uploads/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Image.png" alt="" /></p>

<ul>
  <li>homepage: <a href="http://www.disneyresearch.com/publication/facedirector/">http://www.disneyresearch.com/publication/facedirector/</a></li>
  <li>paper: <a href="http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf">http://disneyresearch.s3-us-west-1.amazonaws.com/wp-content/uploads/20151210174750/FaceDirector-Continuous-Control-of-Facial-Performance-in-Video-Paper.pdf</a></li>
</ul>

<p><strong>Real-time Expression Transfer for Facial Reenactment</strong></p>

<p><img src="http://graphics.stanford.edu/~niessner/papers/2015/10face/teaser.jpg" alt="" /></p>

<ul>
  <li>homepage: <a href="http://graphics.stanford.edu/~niessner/thies2015realtime.html">http://graphics.stanford.edu/~niessner/thies2015realtime.html</a></li>
  <li>paper: <a href="http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf">http://graphics.stanford.edu/~niessner/papers/2015/10face/thies2015realtime.pdf</a></li>
</ul>

<p><strong>Photo Stylistic Brush: Robust Style Transfer via Superpixel-Based Bipartite Graph</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1606.03871">http://arxiv.org/abs/1606.03871</a></li>
</ul>

<h1 id="projects">Projects</h1>

<p><strong>OpenBR: Open Source Biometrics, Face Recognition, Age Estimation, Gender Estimation</strong></p>

<p><img src="http://openbiometrics.org/diagram.png" alt="" /></p>

<ul>
  <li>homepage: <a href="http://openbiometrics.org/">http://openbiometrics.org/</a></li>
  <li>github: <a href="https://github.com/biometrics/openbr">https://github.com/biometrics/openbr</a></li>
  <li>docs: <a href="http://openbiometrics.org/docs/index.html">http://openbiometrics.org/docs/index.html</a></li>
</ul>

<h1 id="resources">Resources</h1>

<p><strong>Awesome Computer Vision</strong></p>

<ul>
  <li>github: <a href="https://github.com/jbhuang0604/awesome-computer-vision">https://github.com/jbhuang0604/awesome-computer-vision</a></li>
</ul>

<p><strong>Resources: Visual Recognition and Search</strong></p>

<ul>
  <li>intro: “Non-exhaustive list of state-of-the-art implementations related to visual recognition and search”</li>
  <li>blog: <a href="http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html">http://rogerioferis.com/VisualRecognitionAndSearch2014/Resources.html</a></li>
</ul>

<h1 id="libraries">Libraries</h1>

<p><strong>BoofCV: an open source Java library for real-time computer vision and robotics applications</strong></p>

<p><a href="http://boofcv.org/index.php?title=Main_Page">http://boofcv.org/index.php?title=Main_Page</a></p>

<p><strong>tracking.js: A modern approach for Computer Vision on the web</strong></p>

<ul>
  <li>homepage: <a href="https://trackingjs.com/">https://trackingjs.com/</a></li>
  <li>github: <a href="https://github.com/eduardolundgren/tracking.js/">https://github.com/eduardolundgren/tracking.js/</a></li>
</ul>

<p><strong>FastCV Computer Vision SDK</strong></p>

<ul>
  <li>homepage: <a href="https://developer.qualcomm.com/software/fastcv-sdk">https://developer.qualcomm.com/software/fastcv-sdk</a></li>
</ul>

<h1 id="datasets">Datasets</h1>

<p><strong>CVonline: Image Databases</strong></p>

<p><a href="http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm">http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm</a></p>

<p><strong>Yet Another Computer Vision Index To Datasets (YACVID)</strong></p>

<p><a href="http://riemenschneider.hayko.at/vision/dataset/">http://riemenschneider.hayko.at/vision/dataset/</a></p>

<h1 id="blogs">Blogs</h1>

<p><strong>From feature descriptors to deep learning: 20 years of computer vision</strong></p>

<ul>
  <li>blog: <a href="http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html">http://www.computervisionblog.com/2015/01/from-feature-descriptors-to-deep.html</a></li>
</ul>

<table>
  <tbody>
    <tr>
      <td>**Unsupervised Computer Vision: The State of the Art</td>
      <td>Stitch Fix Technology – Multithreaded**</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>blog: <a href="http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art">http://multithreaded.stitchfix.com/blog/2016/02/04/computer-vision-state-of-the-art</a></li>
  <li>slides: <a href="http://pan.baidu.com/s/1c0Sxzvq">http://pan.baidu.com/s/1c0Sxzvq</a></li>
</ul>

<p><strong>Exploring Computer Vision</strong></p>

<ul>
  <li>(Part I): Convolutional Neural Networks: <a href="https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/">https://indico.io/blog/exploring-computer-vision-convolutional-neural-nets/</a></li>
  <li>(Part II): Transfer Learning: <a href="https://indico.io/blog/exploring-computer-vision-transfer-learning/">https://indico.io/blog/exploring-computer-vision-transfer-learning/</a></li>
</ul>

<h1 id="conferences">Conferences</h1>

<p><strong>SIGGRAPH 2016 papers on the web</strong></p>

<p><a href="http://kesen.realtimerendering.com/sig2016.html">http://kesen.realtimerendering.com/sig2016.html</a></p>

    <div class="bdsharebuttonbox">
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a>
        <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a>
        <a href="#" class="bds_mail" data-cmd="mail" title="分享到邮件分享"></a>
        <a href="#" class="bds_more" data-cmd="more"></a>
    </div>
    <nav class="article-previous fn-clear">
        
        
    </nav>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES * * */
      var disqus_shortname = 'andrechang67';

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>

                </div>

                <div class="aside">
                    <div class="aside-contact">
                        <h4 class="title">About me</h4>
                        <div class="det fn-clear">
                            <div class="det-image">
                                <img src="/images/header.jpg" />
                            </div>
                            <div class="det-text">
                                <p>Ola</p>
                            </div>
                        </div>
                    </div>

                    <div class="aside-item">
                        <h4 class="title">Recent Posts</h4>
                        <ul class="list">
                            
                                <li><a href="http://andrechang.github.io/blog/development/2016/10/08/linux-tricks.html" title="My First Normal Post on Jekyll" rel="bookmark">My First Normal Post on Jekyll</a></li>
                            
                                <li><a href="http://andrechang.github.io/getting/started/2016/08/31/microzed-setup.html" title="MicroZedboard setup" rel="bookmark">MicroZedboard setup</a></li>
                            
                                <li><a href="http://andrechang.github.io/dualboot/2016/08/31/dualboot.html" title="dualboot setup" rel="bookmark">dualboot setup</a></li>
                            
                                <li><a href="http://andrechang.github.io/aprendizado/de/maquina/2016/08/04/Aprendendo-a-aprender.html" title="Aprendendo a aprender" rel="bookmark">Aprendendo a aprender</a></li>
                            
                                <li><a href="http://andrechang.github.io/vim/2016/05/31/vim.html" title="Good to know in Vim" rel="bookmark">Good to know in Vim</a></li>
                            
                                <li><a href="http://andrechang.github.io/computer_vision/2016/03/03/example.html" title="fgsfgsf" rel="bookmark">fgsfgsf</a></li>
                            
                        </ul>
                    </div>

                    <div class="aside-item">
                        <h4 class="title">Links</h4>
                        <ul class="list">
                            
                                
                            
                                
                            
                        </ul>
                    </div>
                </div>
            </div>
        </div>        
        
        <div class="foot">
            <div class="footer">
                <p>A blog template forked from <a href="https://github.com/zJiaJun/zJiaJun.github.io" target="_blank">zJiaJun</a>. Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a>.</p>
            </div>
        </div>

        <script type="text/javascript" src="http://ajax.useso.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
        
        
        
        <!-- mathjax -->
        <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
        <!-- Search in CSE home -->
        <script>
        (function() {
            var cx = '003287793477459687163:n59nxpgejxy';
            var gcse = document.createElement('script');
            gcse.type = 'text/javascript';
            gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
                '//cse.google.com/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(gcse, s);
        })();
        </script>
        <gcse:search></gcse:search>

        <!-- jekyll-table-of-contents -->
        
        <!-- <script src="http://andrechang.github.io/javascript/jquery-2.1.4.min.js" type="text/javascript"></script> -->
        <script src="http://andrechang.github.io/javascript/toc.js" type="text/javascript"></script>
        <!--
        <link rel="stylesheet" href="http://andrechang.github.io/css/bootstrap.min.css">
        <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
         -->

        <!-- Script to display table of content -->
        <script type="text/javascript">
        $(document).ready(function() {
            $('#toc').toc({ showEffect: 'slideDown' });
        }); </script>
        
    </body>
</html>